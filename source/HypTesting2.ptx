<?xml version="1.0" encoding="UTF-8"?>
<section xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="sec_hyptestprocedure">
<title>Hypothesis Testing Procedure</title>


<introduction>
	<p>
		The <m>P</m>-value approach involves determining "likely" or "unlikely" by determining the probability <emdash/> assuming the null hypothesis were true <emdash/> of observing a more extreme test statistic in the direction of the alternative hypothesis than the one observed. If the <m>P</m>-value is small, say less than (or equal to) <m>\alpha</m>, then it is "unlikely." And, if the <m>P</m>-value is large, say more than <m>\alpha</m>, then it is "likely."
	</p>
	<p>
		If the <m>P</m>-value is less than (or equal to) <m>\alpha</m>, then the null hypothesis is rejected in favor of the alternative hypothesis. And, if the <m>P</m>-value is greater than <m>\alpha</m>, then the null hypothesis is not rejected.
	</p>
	<p>
		Specifically, the four steps involved in using the <m>P</m>-value approach to conducting any hypothesis test are:
		<ol>
			<li>Specify the null and alternative hypotheses.</li>
			<li> 
				Using the sample data and assuming the null hypothesis is true, calculate the value of the test statistic. Again, to conduct the hypothesis test for the population mean <m>\mu</m>, we use the <m>t</m>-statistic <m>t^*=\frac{\xbar-\mu}{s/\sqrt{n}}</m> which follows a <m>t</m>-distribution with <m>n - 1</m> degrees of freedom.
			</li>
			<li>
				Using the known distribution of the test statistic, calculate the <em><m>P</m>-value</em>: "If the null hypothesis is true, what is the probability that we'd observe a more extreme test statistic in the direction of the alternative hypothesis than we did?" (Note how this question is equivalent to the question answered in criminal trials: "If the defendant is innocent, what is the chance that we'd observe such extreme criminal evidence?")
			</li>
			<li>
				Set the significance level, <m>\alpha</m>, the probability of making a Type I error to be small -- 0.01, 0.05, or 0.10. Compare the <m>P</m>-value to <m>\alpha</m>. If the <m>P</m>-value is less than (or equal to) <m>\alpha</m>, reject the null hypothesis in favor of the alternative hypothesis. If the <m>P</m>-value is greater than <m>\alpha</m>, do not reject the null hypothesis.
			</li>
		</ol>
	</p>
</introduction>

<subsection>
	<title>Mean GPA</title>
	<introduction>
		<p>
			In our example concerning the mean grade point average, suppose that our random sample of <m>n = 15</m> students majoring in mathematics yields a test statistic <m>t^*</m> equaling 2.5. Since <m>n = 15</m>, our test statistic <m>t^*</m> has <m>n - 1= 14</m> degrees of freedom. Also, suppose we set our significance level <m>\alpha</m> at 0.05, so that we have only a 5% chance of making a Type I error.
		</p>
	</introduction>
	<subsubsection>
		<title>Right Tailed</title>
		<p>
			The <m>P</m>-value for conducting the <term>right-tailed</term> test <m>H_0 : \mu = 3</m> versus <m>H_A : \mu > 3</m> is the probability that we would observe a test statistic greater than <m>t^* = 2.5</m> if the population mean really were 3. Recall that probability equals the area under the probability curve. The <m>P</m>-value is therefore the area under a <m>t_{n - 1} = t_{14}</m> curve and to the right of the test statistic <m>t^* = 2.5</m>. It can be shown using statistical software that the <m>P</m>-value is 0.0127. The graph depicts this visually.
		</p>
		<sidebyside width="80%">
			<image source="hyparea_right.png">
			<description>Area under a t distribution to the right of 2.5</description>
			</image>
		</sidebyside>
		<p>
			The <m>P</m>-value, 0.0127, tells us it is "unlikely" that we would observe such an extreme test statistic <m>t^*</m> in the direction of <m>H_A</m> if the null hypothesis were true. Therefore, our initial assumption that the null hypothesis is true must be incorrect. That is, since the <m>P</m>-value, 0.0127, is less than <m>\alpha = 0.05</m>, we reject the null hypothesis <m>H_0 : \mu = 3</m> in favor of the alternative hypothesis <m>H_A : \mu > 3</m>.
		</p>
		<aside>
			Note that we would not reject <m>H_0 : \mu = 3</m> in favor of <m>H_A : \mu > 3</m> if we lowered our willingness to make a Type I error to <m>\alpha = 0.01</m> instead, as the <m>P</m>-value, 0.0127, is then greater than <m>\alpha = 0.01</m>.
		</aside>
	</subsubsection>
	<subsubsection>
		<title>Left Tailed</title>
		<p>
			In our example concerning the mean grade point average, suppose that our random sample of <m>n = 15</m> students majoring in mathematics yields a test statistic <m>t^*</m> instead equaling -2.5. The <m>P</m>-value for conducting the left-tailed test <m>H_0 : \mu = 3</m> versus <m>H_A: \mu &lt; 3</m> is the probability that we would observe a test statistic less than <m>t^* = -2.5</m> if the population mean <m>\mu</m> really were 3. The <m>P</m>-value is therefore the area under a <m>t_{n - 1} = t_{14}</m> curve and to the <em>left</em> of the test statistic <m>t^* = -2.5</m>. It can be shown using statistical software that the <m>P</m>-value is 0.0127. The graph depicts this visually.
		</p>
		<sidebyside width="80%">
			<image source="hyparea_left.png">
			<description>Area under a <m>t</m> distribution to the left of -2.5</description>
			</image>
		</sidebyside>
		<p>
			The <m>P</m>-value, 0.0127, tells us it is "unlikely" that we would observe such an extreme test statistic <m>t^*</m> in the direction of <m>H_A</m> if the null hypothesis were true. Therefore, our initial assumption that the null hypothesis is true must be incorrect. That is, since the <m>P</m>-value, 0.0127, is less than <m>\alpha = 0.05</m>, we reject the null hypothesis <div>H_0 : \mu = 3</div> in favor of the alternative hypothesis <m>H_A : \mu &lt; 3</m>.
		</p>
		<aside>
			Note that we would not reject <m>H_0: \mu = 3</m> in favor of <m>H_A: \mu &lt; 3</m> if we lowered our willingness to make a Type I error to <m>\alpha = 0.01</m> instead, as the <m>P</m>-value, 0.0127, is then greater than <m>\alpha = 0.01</m>.
		</aside>
	</subsubsection>
	<subsubsection>
		<title>Two Tailed</title>
		<p>
			In our example concerning the mean grade point average, suppose again that our random sample of <m>n = 15</m> students majoring in mathematics yields a test statistic <m>t^*</m> instead equaling -2.5. The <m>P</m>-value for conducting the two-tailed test <m>H_0: \mu = 3</m> versus <m>H_A: \mu \neq 3</m> is the probability that we would observe a test statistic less than -2.5 or greater than 2.5 if the population mean <m>\mu</m> really were 3. That is, the two-tailed test requires taking into account the possibility that the test statistic could fall into either tail (and hence the name "two-tailed" test). The <m>P</m>-value is therefore the area under a <m>t_{n - 1} = t_{14}</m> curve to the left of -2.5 and to the right of the 2.5. It can be shown using statistical software that the <m>P</m>-value is 0.0127 + 0.0127, or 0.0254. The graph depicts this visually.
		</p>
		<sidebyside>
			<image source="hyparea_twotail.png">
			<description>Area under a <m>t</m> distribution to the right of 2.5 and to the left of -2.5</description>
			</image>
		</sidebyside>
		<p>
			Note that the <m>P</m>-value for a two-tailed test is always two times the <m>P</m>-value for either of the one-tailed tests. The <m>P</m>-value, 0.0254, tells us it is "unlikely" that we would observe such an extreme test statistic <m>t^*</m> in the direction of <m>H_A</m> if the null hypothesis were true. Therefore, our initial assumption that the null hypothesis is true must be incorrect. That is, since the <m>P</m>-value, 0.0254, is less than <m>\alpha = 0.05</m>, we reject the null hypothesis <m>H_0: \mu = 3</m> in favor of the alternative hypothesis <m>H_A: Î¼ \neq 3</m>.
		</p>
		<aside>
			Note that we would not reject <m>H_0: \mu = 3</m> in favor of <m>H_A: \mu \neq 3</m> if we lowered our willingness to make a Type I error to <m>\alpha = 0.01</m> instead, as the <m>P</m>-value, 0.0254, is then greater than <m>\alpha = 0.01</m>.
		</aside>
	</subsubsection>
	<p>
		Now that we have reviewed the <m>P</m>-value procedures for each of three possible hypotheses, in the next section we look at three new examples <emdash/> one of a right-tailed test, one of a left-tailed test, and one of a two-tailed test.
	</p>
	<p>
		The good news is that, whenever possible, we will take advantage of the test statistics and <m>P</m>-values reported in statistical software, such as R, to conduct our hypothesis tests in this course.
	</p>
</subsection>
<subsection>
	<title>Supplemental Materials</title>
	<p>
		For another discussion of the <m>t</m>-distribution, watch the following video:
		<ul>
			<li> <url href="http://www.learner.org/courses/againstallodds/unitpages/unit26.html">Small Sample Inference for One Mean </url>, part of `against all odds' at Annenberg Learner.
			</li>
		</ul>
	</p>	
</subsection>

</section>